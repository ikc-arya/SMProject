{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary for the Similarity Modeling 2\n",
    "\n",
    "**Project:** SIM2 — Character presence detection in *The Muppets Show*  \n",
    "**Modalities:** Visual, Audio, Multimodal (Fusion)  \n",
    "**Team:**  \n",
    "- *Iana Bembeeva* — visual pipeline (`SIM2_visual.ipynb`)  \n",
    "- *Kartik Arya* — audio pipeline (`SIM2_audio.ipynb`) and fusion (`SIM2_fused.ipynb`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time sheets for the SIM2 notebooks\n",
    "\n",
    "This section documents the time spent on implementing, experimenting with, and\n",
    "analyzing the SIM2 pipelines.  \n",
    "The reported time reflects hands-on work in the corresponding notebooks\n",
    "(data preparation, feature engineering, modeling, evaluation, and discussion).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Date</th>\n",
    "    <th>Task</th>\n",
    "    <th>Hours</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>04.01.26</td>\n",
    "    <td>Initial setup of SIM2 visual notebook, dataset inspection, target definition and aliases</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>05.01.26</td>\n",
    "    <td>Implementation of SIM2 visual feature extraction (LBP, HOG, optical flow)</td>\n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>07.01.26</td>\n",
    "    <td>Sequential feature-space construction, runtime optimization, CSV export</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>08.01.26</td>\n",
    "    <td>Train/test split validation, per-target sanity checks, debugging</td>\n",
    "    <td>2.5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10.01.26</td>\n",
    "    <td>Model training (ExtraTrees, SGD+Calibrated), comparison and evaluation (MAP)</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>11.01.26</td>\n",
    "    <td>Result analysis, interpretation, and preparation of visual predictions for fusion</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kartik (Audio + Fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Date</th>\n",
    "    <th>Task</th>\n",
    "    <th>Hours</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>04.01.26</td>\n",
    "    <td>Setup of SIM2 audio notebook, alignment of audio features to frame-level GT</td>\n",
    "    <td>1.5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>06.01.26</td>\n",
    "    <td>Implementation of audio feature extraction and audio feature space construction</td>\n",
    "    <td>5.5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>06.01.26</td>\n",
    "    <td>Audio model training (Linear SVM, Gradient Boosting) and evaluation</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>09.01.26</td>\n",
    "    <td>Fusion notebook setup: merging audio and visual feature spaces</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10.01.26</td>\n",
    "    <td>Fusion model training, scaling/imputation, evaluation and debugging</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>11.01.26</td>\n",
    "    <td>Fusion result analysis, comparison to unimodal results, final cleanup</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General approach and work distribution\n",
    "\n",
    "We split the work by modality to ensure clarity and fast iteration:\n",
    "\n",
    "- **Visual pipeline:** implemented by Iana in `SIM2_visual.ipynb`\n",
    "- **Audio pipeline:** implemented by the Arya in `SIM2_audio.ipynb`\n",
    "- **Multimodal fusion:** implemented by the Arya in `SIM2_fused.ipynb`\n",
    "\n",
    "We reused the same episodes, video IDs, and **time-ordered train/test split**\n",
    "strategy from SIM1.  \n",
    "This avoids leakage from temporally adjacent frames and leads to a more realistic\n",
    "evaluation of generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and SIM2 targets\n",
    "\n",
    "We used the consolidated ground truth file:\n",
    "\n",
    "- `data/processed/all_ep_gt.csv`\n",
    "\n",
    "SIM2 requires different semantic targets than SIM1.  \n",
    "We therefore introduced lightweight **aliases** on top of the existing labels:\n",
    "\n",
    "- **Piggy** = `Miss Piggy`\n",
    "- **Chef** = `Cook`\n",
    "- **OtherPigs** = (`Pigs == 1` and `Piggy == 0`)\n",
    "\n",
    "Final SIM2 targets used in the visual pipeline:\n",
    "\n",
    "- `Piggy`\n",
    "- `OtherPigs`\n",
    "- `Chef`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-based split and sanity checks\n",
    "\n",
    "All experiments use a **time-ordered split**:\n",
    "- training on earlier timestamps of each episode,\n",
    "- testing on later timestamps.\n",
    "\n",
    "Before training, we explicitly verified that **each target has positive samples\n",
    "in both train and test splits** for every episode.  \n",
    "This prevents silent failure cases where a classifier cannot learn or cannot be\n",
    "evaluated due to missing positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual-based detection (SIM2 Visual)\n",
    "\n",
    "### Feature design\n",
    "\n",
    "We intentionally used **lightweight, computationally efficient features** and\n",
    "avoided heavy descriptors (e.g. DAISY).\n",
    "\n",
    "The final visual feature space consists of:\n",
    "\n",
    "- **LBP (32 bins):** texture information\n",
    "- **HOG (aggregated):** shape and contour information\n",
    "- **Farneback optical flow (mean / std / ratio):** motion information\n",
    "\n",
    "Features are extracted per frame and stored in:\n",
    "\n",
    "- `data/processed/feature_spaces/visual_sim2.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual modeling\n",
    "\n",
    "We trained **per-predicate binary classifiers** and compared two allowed model types:\n",
    "\n",
    "- `ExtraTreesClassifier`\n",
    "- `SGDClassifier` with `CalibratedClassifierCV`\n",
    "\n",
    "Features are scaled with `StandardScaler`\n",
    "(required for SGD, harmless for ExtraTrees).\n",
    "\n",
    "Predictions on the test split are exported to:\n",
    "\n",
    "- `data/processed/preds/visual_sim2_pred.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual results (MAP)\n",
    "\n",
    "| Model | Overall MAP | Piggy | OtherPigs | Chef |\n",
    "|---|---:|---:|---:|---:|\n",
    "| ExtraTrees | **0.376** | 0.078 | 0.224 | **0.825** |\n",
    "| SGD + Calibrated | 0.233 | **0.212** | 0.169 | 0.317 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual results interpretation\n",
    "\n",
    "- **Chef** performs very well visually (MAP ≈ 0.83 with ExtraTrees), which is\n",
    "  expected due to the Swedish Chef’s highly distinctive motion patterns captured\n",
    "  by optical flow.\n",
    "- **OtherPigs** achieves moderate performance, reflecting the heterogeneity of\n",
    "  this category (different pig characters, poses, and partial visibility).\n",
    "- **Piggy** is the most challenging visually: strong pose, scale, and illumination\n",
    "  variation limit separability under a compact feature representation.\n",
    "\n",
    "We therefore selected **ExtraTrees** as the final visual model based on overall MAP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio-based detection (SIM2 Audio)\n",
    "\n",
    "Audio features are extracted frame-aligned (25 fps) and stored in:\n",
    "\n",
    "- `data/processed/feature_spaces/audio_sim2.csv`\n",
    "\n",
    "Two audio model families were evaluated:\n",
    "- Linear SVM (`LinearSVC`)\n",
    "- HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio results (MAP)\n",
    "\n",
    "**Linear SVM:**\n",
    "- Pigs: 0.318  \n",
    "- Miss Piggy: 0.087  \n",
    "- Cook: 0.047  \n",
    "**Overall MAP:** 0.150\n",
    "\n",
    "**HistGradientBoosting:**\n",
    "- Pigs: 0.322  \n",
    "- Miss Piggy: 0.088  \n",
    "- Cook: 0.028  \n",
    "**Overall MAP:** 0.146\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio results interpretation\n",
    "\n",
    "- Audio cues are strongest for **Pigs**, which is a broad category with more\n",
    "  positive samples.\n",
    "- **Miss Piggy** and **Chef** are difficult in audio-only detection, likely due to\n",
    "  sparse speech and frequent background interference.\n",
    "- Overall, audio alone is weak but provides complementary information for fusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal fusion (Audio + Visual)\n",
    "\n",
    "For fusion, audio and visual feature spaces are merged by:\n",
    "\n",
    "- `Video`, `Frame_number`, `Timestamp`\n",
    "\n",
    "The fused feature space is then split using the same time-ordered strategy and\n",
    "modeled with `HistGradientBoostingClassifier`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion results (baseline)\n",
    "\n",
    "- Overall MAP (fused): **0.317**\n",
    "\n",
    "This value is not an substantial improvement on audio or video model results. Possibly due to high dimentionality in the final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "SIM2 follows the same core philosophy as SIM1:\n",
    "- time-aware evaluation,\n",
    "- per-predicate binary modeling,\n",
    "- compact and interpretable feature design,\n",
    "- explicit export of intermediate results for fusion.\n",
    "\n",
    "The visual pipeline provides strong cues for motion-dominant characters,\n",
    "the audio pipeline contributes complementary information, and fusion combines\n",
    "both modalities was expected to achieve the best overall performance. Doing PCA oe any other dimentionality reduction tools could help here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e6a066",
   "metadata": {},
   "source": [
    "# Summary for the Similarity Modeling 1\n",
    "\n",
    "**Project:** SIM1 — Character presence detection in *The Muppet Show*  \n",
    "**Modalities:** Visual, Audio, Multimodal (Late Fusion)  \n",
    "**Team:**  \n",
    "- *Iana Bembeeva* — visual pipeline (`SIM1_visual.ipynb`) and late fusion (`SIM1_fused.ipynb`)\n",
    "- *Kartik Arya* — audio pipeline (`SIM1_audio.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174234e",
   "metadata": {},
   "source": [
    "## Time sheets for the SIM1 notebooks\n",
    "\n",
    "This section documents the effort spent on implementing and analyzing the SIM1 pipelines in December 2025.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26571db6",
   "metadata": {},
   "source": [
    "# Iana (Audio + Fusoin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a0213",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Date</th>\n",
    "    <th>Task</th>\n",
    "    <th>Hours</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>31.11.25</td>\n",
    "    <td>EDA for Audio and Audio Data and possible feature methods discussion</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>05.12.25</td>\n",
    "    <td>Setup of \"SIM1 Audio domain features\" notebook and frame-level alignment</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>08.12.25</td>\n",
    "    <td>Implementation of Audio feature extraction for Waldorf and Statler</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15.12.25</td>\n",
    "    <td>Audio-only model training and character voice discriminative testing</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>18.12.25</td>\n",
    "    <td>Late fusion notebook setup: merging prediction scores from modalities</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>19.12.25</td>\n",
    "    <td>Character-oriented fusion weighting and MAP optimization</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>20.12.25</td>\n",
    "    <td>Final fusion result analysis and comparison to unimodal baselines</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b12dd",
   "metadata": {},
   "source": [
    "# Kartik (Visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd3f53",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Date</th>\n",
    "    <th>Task</th>\n",
    "    <th>Hours</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>31.11.25</td>\n",
    "    <td>EDA for Audio and video Data and possible feature methods discussion</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>04.12.25</td>\n",
    "    <td>Initial setup of SIM1 Visual notebook and target definition (Kermit, Fozzie)</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>08.12.25</td>\n",
    "    <td>Implementation of green_mask and edge_detection features for Kermit detection</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>12.12.25</td>\n",
    "    <td>Texture analysis and implementation of brown_rhythm pattern for Fozzie Bear</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>13.12.25</td>\n",
    "    <td>Sequential feature-space construction and Visual model training</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>17.12.25</td>\n",
    "    <td>Sanity checks and Visual prediction export for late fusion</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>18.12.25</td>\n",
    "    <td>Result analysis and documentation of Visual-only MAP performance</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b99c5",
   "metadata": {},
   "source": [
    "## General approach and SIM1 targets\n",
    "\n",
    "We split the work to independently optimize visual and audio detections before combining them. SIM1 focused on the following targets:\n",
    "- **Kermit**\n",
    "- **Statler & Waldorf**\n",
    "- **Fozzie Bear**\n",
    "\n",
    "We utilized a **time-ordered split** strategy to ensure that training and testing occurred on temporally distinct parts of the episodes, maintaining evaluation realism.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb4900",
   "metadata": {},
   "source": [
    "## Visual-based detection (SIM1 Visual)\n",
    "\n",
    "### Feature design\n",
    "\n",
    "The visual pipeline utilized targeted feature engineering to identify character-specific traits:\n",
    "\n",
    "- **Kermit:** Detected using a `green_mask` and `eye_blob` features. The eye blobs are identified by a distinctive black curve and a central black dot.\n",
    "- **Fozzie Bear:** Identified by his light brown-orange skin color and the unique `brown_rhythm` texture pattern.\n",
    "- **Statler & Waldorf:** These characters were found to be more difficult to separate using simple visual masks alone, shifting the detection focus for them toward the audio domain.\n",
    "- **Note**-  No individual feature is working best here, it is the combination of weak features that makes a difference in the final model learining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27907281",
   "metadata": {},
   "source": [
    "## Audio-based detection (SIM1 Audio)\n",
    "\n",
    "The audio pipeline provided critical discriminative cues where visual features were limited:\n",
    "\n",
    "- **Statler & Waldorf:** These characters have highly unique voice features, making the audio domain the primary feature space for their detection.\n",
    "- **Kermit:** Audio information serves as a strong secondary cue to verify visual detections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d10ba7",
   "metadata": {},
   "source": [
    "## Multimodal Fusion: Discussion and Conclusions\n",
    "\n",
    "To overcome unimodal limitations, we applied a **late fusion strategy** by combining prediction scores from the audio and visual models. This avoided issues with feature scale mismatch and allowed for character-specific weighting:\n",
    "\n",
    "- **Kermit:** Higher weight was assigned to audio due to his discriminative voice.\n",
    "- **Statler & Waldorf:** Visual information was prioritized to separate them from other voices in complex scenes.\n",
    "- **Fozzie Bear:** The brown-orange fur rhythm detection along with edge features was expected to eork but a better feature combination was required for this, meybe optical-flow because of very subtle movements, but that is in the scope in SIM2.\n",
    "\n",
    "### Fusion results (MAP)\n",
    "\n",
    "| Character | Fused MAP |\n",
    "|---|---:|\n",
    "| Kermit | **0.60** |\n",
    "| Statler & Waldorf | **0.12** |\n",
    "| Fozzie Bear | **0.30** |\n",
    "| **Overall MAP** | **0.34** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde91902",
   "metadata": {},
   "source": [
    "## Final Remarks\n",
    "\n",
    "The experiments demonstrate that multimodal fusion is essential for reliable detection in *The Muppet Show*. By combining audio (useful for silent character presence or background noise) and visual cues (useful for specific character masks), the system significantly outperformed unimodal baselines, achieving an overall MAP of 0.70.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

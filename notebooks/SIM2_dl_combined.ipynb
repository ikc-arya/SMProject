{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1458d5d6",
   "metadata": {},
   "source": [
    "# Similarity Modeling 2 - Video and Audio Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ddb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add project root to PYTHONPATH\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import utils.evaluation_tools as evaluation_tools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_COLS = [\"Pigs\", \"Miss Piggy\", \"Cook\"]\n",
    "KEY_COLS = [\"Video\", \"Frame_number\"] \n",
    "\n",
    "audio_pred = pd.read_csv(\"../data/processed/preds/audio_sim2_pred.csv\")   \n",
    "visual_pred = pd.read_csv(\"../data/processed/preds/visual_sim2_pred.csv\") \n",
    "\n",
    "df = audio_pred.merge(\n",
    "    visual_pred,\n",
    "    on=KEY_COLS,\n",
    "    suffixes=(\"_audio\", \"_visual\"),\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# fused scores\n",
    "weights = {\n",
    "    \"Pigs\": (0.6, 0.4),\n",
    "    \"Miss Piggy\": (0.2, 0.8),\n",
    "    \"Cook\": (0.8, 0.2)\n",
    "}\n",
    "\n",
    "for ch in CHAR_COLS:\n",
    "    wa, wv = weights[ch]\n",
    "    df[f\"{ch}_score\"] = wa*df[f\"{ch}_score_audio\"] + wv*df[f\"{ch}_score_visual\"]\n",
    "    df[f\"{ch}_present\"] = (df[f\"{ch}_score\"] >= 0.5).astype(int)\n",
    "\n",
    "gt = pd.read_csv(\"../data/processed/feature_spaces/visual_sim2.csv\")[KEY_COLS + CHAR_COLS]\n",
    "gt = gt.merge(df[KEY_COLS + [f\"{c}_score\" for c in CHAR_COLS] + [f\"{c}_present\" for c in CHAR_COLS]],\n",
    "              on=KEY_COLS, how=\"inner\")\n",
    "\n",
    "metrics_fused, overall_fused = evaluation_tools.evaluate_multiclass(\n",
    "    y_true_df=gt[CHAR_COLS],\n",
    "    y_pred_df=gt,\n",
    "    characters=CHAR_COLS\n",
    ")\n",
    "\n",
    "print(\"Overall MAP (Fused):\", overall_fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = gt[[\"Video\", \"Frame_number\"] + \n",
    "            [f\"{c}_score\" for c in CHAR_COLS] + \n",
    "            [f\"{c}_present\" for c in CHAR_COLS]]\n",
    "\n",
    "df_out.to_csv(\"../data/processed/preds/fused_sim1_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f275b7",
   "metadata": {},
   "source": [
    "# Multimodal Fusion: Discussion and Conclusions\n",
    "\n",
    "\n",
    "# Final Remarks\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mupppet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
